# inject a packet delay of 0-90ms while increasing the otel metric inverval to 1s
experiment:
  version: 0.0.1
  orchestrator: kubernetes
  services:
    jaeger: 
      name: astronomy-shop-jaeger-query
      namespace: system-under-evaluation
    prometheus: [
      { name: astronomy-shop-prometheus-server, namespace: system-under-evaluation, target: sue },
      { name: kube-prometheus-kube-prome-prometheus, namespace: oxn-external-monitoring, target: oxn },
    ]
  responses:
    - frontend_traces:
        type: trace
        service_name: frontend 
        left_window: 300s
        right_window: 300s
        limit: 10000
    - recommendation_traces:
        type: trace
        service_name: recommendationservice 
        left_window: 300s
        right_window: 300s
        limit: 10000
    - system_CPU:
        type: metric
        metric_name: sum(rate(container_cpu_usage_seconds_total{namespace="system-under-evaluation"}[1m]))
        left_window: 300s
        right_window: 300s
        step: 1
        target: oxn
    - recommendation_deployment_CPU:
        type: metric
        metric_name: sum(rate(container_cpu_usage_seconds_total{namespace="system-under-evaluation", pod=~"astronomy-shop-recommendationservice.*"}[90s])) by (pod)
        left_window: 300s
        right_window: 300s
        step: 1
        target: oxn
    - recommendationservice_kepler_package_joules:
        type: metric
        metric_name: sum by (pod_name, container_namespace) (irate(kepler_container_package_joules_total{container_namespace=~"system-under-evaluation", pod_name=~"astronomy-shop-recommendationservice.*"}[1m]))
        left_window: 300s
        right_window: 300s
        step: 1
        target: oxn
    - recommendationservice_kepler_dram_joules:
        type: metric
        metric_name: sum by (pod_name, container_namespace) (irate(kepler_container_dram_joules_total{container_namespace=~"system-under-evaluation", pod_name=~"astronomy-shop-recommendationservice.*"}[1m]))
        left_window: 300s
        right_window: 300s
        step: 1
        target: oxn
    - recommendationservice_kepler_other_joules:
        type: metric
        metric_name: sum by (pod_name, container_namespace) (irate(kepler_container_other_joules_total{container_namespace=~"system-under-evaluation", pod_name=~"astronomy-shop-recommendationservice.*"}[1m]))
        left_window: 300s
        right_window: 300s
        step: 1
        target: oxn
    - latency_frontend_95_percentile:
        type: metric
        metric_name: histogram_quantile(0.95, sum(rate(duration_milliseconds_bucket{service_name="frontend"}[90s])) by (le))
        left_window: 300s
        right_window: 300s
        step: 1
        target: sue
    - latency_recommendationservice_95_percentile:
        type: metric
        metric_name: histogram_quantile(0.95, sum(rate(duration_milliseconds_bucket{service_name="recommendationservice"}[90s])) by (le))
        left_window: 300s
        right_window: 300s
        step: 1
        target: sue
    - recommendations_total:
        type: metric
        metric_name: increase(app_recommendations_counter_total[1m])
        left_window: 300s
        right_window: 300s
        step: 1
        target: sue
    - sampling_rates:
        type: metric
        metric_name: increase(otelcol_processor_probabilistic_sampler_count_traces_sampled[1m])
        left_window: 300s
        right_window: 300s
        step: 1
        target: sue
    - kepler_metric_all_namespace:
        type: metric
        metric_name: sum by (pod_name, container_name, container_namespace, node)(irate(kepler_container_joules_total{container_namespace="system-under-evaluation"}[1m]))
        left_window: 300s
        right_window: 300s
        step: 1
        target: oxn
  treatments:
    #- kill_recommendation_service:
    #    action: kubernetes_kill
    #    params: {
    #      namespace: system-under-evaluation,
    #      label_selector: app.kubernetes.io/component,
    #      label: recommendationservice,
    #      amount_to_kill: 1,
    #    }
    #- stop_loadgen_deployment:
    #    action: scale_deployment
    #    params: {
    #      namespace: system-under-evaluation,
    #      label_selector: app.kubernetes.io/component,
    #      label: loadgenerator,
    #      scale_to: 0,
    #    }
    #- add_security_context:
    #    action: security_context_kubernetes
    #    params: {
    #      namespace: system-under-evaluation,
    #      label_selector: app.kubernetes.io/component,
    #      label: recommendationservice,
    #      capabilities: { add: ["NET_ADMIN"] },
    #    }
    # - delay_treatment:
    #     action: delay
    #     params: {
    #       namespace: system-under-evaluation,
    #       label_selector: app.kubernetes.io/name,
    #       label: astronomy-shop-recommendationservice,
    #       #service_name: node-exporter,
    #       delay_time: 45ms,
    #       delay_jitter: 45ms,
    #       duration: 10m,
    #       interface: eth0,
    #     }
    # - probabilistic_head_sampling_rate:
    #     action: kube_probl
    #     params: {
    #       sampling_percentage: 5.0,
    #       hash_seed: 22,
    #       }
    #- package_lost_treatment:
    #    action: kubernetes_loss
    #    params: {
    #      namespace: system-under-evaluation,
    #      label_selector: app.kubernetes.io/name,
    #      label: astronomy-shop-recommendationservice,
    #      loss_percentage: 15.0,
    #      duration: 10m,
    #      interface: eth0,
    #    }
    - empty_treatment:
        action: empty
        params: {
          duration: 20m,
        }
    #- increase_otel_metric_interval:
    #    action: kubernetes_otel_metrics_interval
    #    params: {
    #      namespace: system-under-evaluation,
    #      label_selector: app.kubernetes.io/component,
    #      label: recommendationservice,
    #      interval: 15s,
    #    }
     #reloading the prometheus config is not as trivial as it seems to be
    #- prometheus_scrape_interval:
    #    action: kubernetes_prometheus_interval
    #    params: {
    #      interval: 5s,
    #      evaluation_interval: 5s,
    #      scrape_timeout: 3s,
    #    }
  sue:
    compose: opentelemetry-demo/docker-compose.yml
    exclude: [loadgenerator]
    required: [{namespace: system-under-evaluation, name: astronomy-shop-prometheus-server}] # {namespace: monitoring, name: not-running-service}
    #required: [{namespace: monitoring, name: grafana}, {namespace: monitoring, name: node-exporter}]
  loadgen:
    run_time: 30m
    max_users: 500
    spawn_rate: 10
    locust_files: [
      { path: /opt/oxn/locust/locust_basic_interaction.py },
      { path: /opt/oxn/locust/locust_otel_demo.py },
      ]
    target:
      name: astronomy-shop-frontendproxy
      namespace: system-under-evaluation
      port: 8080